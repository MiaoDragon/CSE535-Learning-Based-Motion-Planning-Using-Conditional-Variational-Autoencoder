{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('cse535': conda)",
   "display_name": "Python 3.8.5 64-bit ('cse535': conda)",
   "metadata": {
    "interpreter": {
     "hash": "426ee9227c26455faf607ec3a590f915894f1ba5a016c6956515b9ee914a0b72"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "source": [
    "# define CVAE model\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, cond_size, latent_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.mu_network = nn.Sequential(\n",
    "            nn.Linear(input_size+cond_size, 512), nn.PReLU(), nn.Dropout(),\n",
    "            nn.Linear(512, 256), nn.PReLU(), nn.Dropout(),\n",
    "            nn.Linear(256, 32), nn.PReLU(),\n",
    "            nn.Linear(32, latent_size)\n",
    "        )\n",
    "        # we set the covariance matrix to be diag([sigma_1,...,sigma_k])\n",
    "        self.log_sigma_pow2_network = nn.Sequential(\n",
    "            nn.Linear(input_size+cond_size, 512), nn.PReLU(), nn.Dropout(),\n",
    "            nn.Linear(512, 256), nn.PReLU(), nn.Dropout(),\n",
    "            nn.Linear(256, 32), nn.PReLU(),\n",
    "            nn.Linear(32, latent_size)\n",
    "        )\n",
    "        self.output_size = latent_size\n",
    "        self.latent_size = latent_size\n",
    "        self.input_size = input_size\n",
    "        self.cond_size = cond_size\n",
    "    def forward(self, x, y):\n",
    "        # input tensor shape: BxK1, BxK2\n",
    "        input = torch.cat([x,y], dim=1)\n",
    "        mu = self.mu_network(input)\n",
    "        log_sigma_pow2 = self.log_sigma_pow2_network(input)\n",
    "        return mu, log_sigma_pow2\n",
    "\n",
    "    def sample(self, mu, log_sigma_pow2, L):\n",
    "        # given the computed mu, and sigma, obtain L samples by reparameterization\n",
    "        # draw standard normal distribution\n",
    "        # input: Bxk\n",
    "        # return: LxBxk\n",
    "        eps = torch.randn((L,len(mu),self.latent_size))\n",
    "        if log_sigma_pow2.is_cuda:\n",
    "            eps = eps.cuda()\n",
    "        eps = eps * torch.exp(log_sigma_pow2/2)\n",
    "        eps = eps + mu\n",
    "        return eps\n",
    "\n",
    "    def kl_divergence(self, mu, log_sigma_pow2):\n",
    "        # given mu and log(sigma^2), obtain the KL divergence relative to N(0,I)\n",
    "        # using formula from https://stats.stackexchange.com/questions/318748/deriving-the-kl-divergence-loss-for-vaes\n",
    "        # input: BxK\n",
    "        # output: B\n",
    "        res = 1.0 / 2 * (-torch.sum(log_sigma_pow2, dim=1)-self.output_size+\\\n",
    "                         torch.sum(torch.exp(log_sigma_pow2), dim=1)+torch.sum(mu*mu, dim=1))\n",
    "        return res\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_size, cond_size, output_size, sigma=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.mu_network = nn.Sequential(\n",
    "            nn.Linear(latent_size+cond_size, 512), nn.PReLU(), nn.Dropout(),\n",
    "            nn.Linear(512, 256), nn.PReLU(), nn.Dropout(),\n",
    "            nn.Linear(256, 32), nn.PReLU(),\n",
    "            nn.Linear(32, output_size)\n",
    "        )\n",
    "        self.latent_size = latent_size\n",
    "        self.cond_size = cond_size\n",
    "        self.sigma = sigma\n",
    "        self.sigma_2 = sigma*sigma\n",
    "\n",
    "    def forward(self, z, y):\n",
    "        input = torch.cat([z,y],dim=1)\n",
    "        mu = self.mu_network(input)\n",
    "        return mu\n",
    "\n",
    "    def sample(self, mu):\n",
    "        # use the computed mu to generate sample\n",
    "        # input: BxN\n",
    "        eps = torch.randn(mu.size())\n",
    "        if mu.is_cuda:\n",
    "            eps = eps.cuda()\n",
    "        eps = eps * self.sigma + mu\n",
    "        return eps\n",
    "\n",
    "    def generation_loss(self, x, mu):\n",
    "        # input:\n",
    "        # - mu: LxBxN\n",
    "        # - x: BxN\n",
    "        # output: BxN\n",
    "        # formula: 1/L * sum_z log(N(x; mu, sigma^2I))\n",
    "        #       => -1/L \\sum_z 1/2*(x-mu)^T(x-mu)/(sigma^2)\n",
    "        res = - 1.0/2*(x-mu)*(x-mu)/self.sigma_2\n",
    "        res = torch.sum(res, dim=2) # sum up (x-mu)^2\n",
    "        # calculate the mean w.r.t. first dimension (L)\n",
    "        res = torch.mean(res, dim=0)\n",
    "        return res\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, input_size, latent_size, cond_size):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.encoder = Encoder(input_size, cond_size, latent_size)\n",
    "        self.decoder = Decoder(latent_size, cond_size, input_size, sigma=0.1)\n",
    "        self.input_size = input_size\n",
    "        self.latent_size = latent_size\n",
    "        self.cond_size = cond_size\n",
    "\n",
    "    def train_forward(self, x, y, L=10):\n",
    "        # get necessary signals from the input\n",
    "        z_mu, z_log_sigma_pow2 = self.encoder(x, y)\n",
    "        # generate samples of z using the mean and variance\n",
    "        z = self.encoder.sample(z_mu, z_log_sigma_pow2, L)\n",
    "        y_extended = y.repeat(len(z),1).view(-1,self.cond_size)\n",
    "        z = z.view(-1,self.latent_size)  # B and L together first\n",
    "        if x.is_cuda:\n",
    "            z.cuda()\n",
    "        # copy y so we have shape: LxBxc\n",
    "        x_mu = self.decoder(z, y_extended).view(L,-1,self.input_size)\n",
    "        return z_mu,z_log_sigma_pow2, z, x_mu\n",
    "\n",
    "    def gen_forward(self, y):\n",
    "        # randomly sample a latent z\n",
    "        z = torch.randn(len(y),self.latent_size)\n",
    "        if y.is_cuda:\n",
    "            z = z.cuda()\n",
    "        x_mean = self.decoder(z, y)\n",
    "        x = self.decoder.sample(x_mean)\n",
    "        return x\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit testing for encoder\n",
    "# test sample\n",
    "\n",
    "# def sample(self, mu, log_sigma_pow2, L):\n",
    "#     # given the computed mu, and sigma, obtain L samples by reparameterization\n",
    "#     # draw standard normal distribution\n",
    "#     # input: Bxk\n",
    "#     # return: LxBxk\n",
    "input_size = 20\n",
    "cond_size = 2\n",
    "latent_size = 5\n",
    "encoder = Encoder(input_size, cond_size, latent_size)\n",
    "mu = torch.ones((10,5))\n",
    "sigma = torch.abs(torch.randn(10,5))\n",
    "log_sigma_pow2 = torch.log(sigma*sigma)\n",
    "L = 1000\n",
    "z = encoder.sample(mu, log_sigma_pow2, L)\n",
    "\n",
    "\n",
    "# test KL divergence\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(z)\n",
    "unit_testing = False\n",
    "if unit_testing:\n",
    "    print('estimated mean: ')\n",
    "    print(torch.mean(z, dim=0))\n",
    "    print('estimated std: ')\n",
    "    print(torch.std(z, dim=0))\n",
    "    print('true mean:')\n",
    "    print(mu)\n",
    "    print('true std:')\n",
    "    print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "def idx2onehot(idx, n):\n",
    "\n",
    "    assert torch.max(idx).item() < n\n",
    "    if idx.dim() == 1:\n",
    "        idx = idx.unsqueeze(1)\n",
    "\n",
    "    onehot = torch.zeros(idx.size(0), n)\n",
    "    onehot.scatter_(1, idx, 1)\n",
    "\n",
    "    return onehot\n",
    "\n",
    "def main():\n",
    "    batch_size = 32\n",
    "    input_size = 28*28\n",
    "    latent_size = 16\n",
    "    cond_size = 10\n",
    "    learning_rate = 0.001\n",
    "    num_epoch = 20\n",
    "    print_every = 100\n",
    "\n",
    "    device = torch.device('cuda:0')\n",
    "\n",
    "    dataset = MNIST(\n",
    "            root='data', train=True, transform=transforms.ToTensor(),\n",
    "            download=True)\n",
    "    data_loader = DataLoader(\n",
    "        dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    cvae = CVAE(input_size, latent_size, cond_size)\n",
    "    cvae.cuda()\n",
    "    optimizer = torch.optim.Adam(cvae.parameters(), learning_rate)\n",
    "\n",
    "    logs = defaultdict(list)\n",
    "    print('start training...')\n",
    "    for epoch in range(num_epoch):\n",
    "        for iter, (x, y) in enumerate(data_loader):\n",
    "            y = idx2onehot(y, n=10)\n",
    "            x = x.view(-1,28*28)\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            #x, y = x.to(device), y.to(device)\n",
    "            z_mu,z_log_sigma_pow2, z, x_mu = cvae.train_forward(x, y, L=10)\n",
    "            kl_divergence = cvae.encoder.kl_divergence(z_mu, z_log_sigma_pow2)\n",
    "            generation_loss = cvae.decoder.generation_loss(x, x_mu)\n",
    "            loss_i = -generation_loss + kl_divergence\n",
    "            loss_i = torch.mean(loss_i)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_i.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            logs['loss'].append(loss_i.item())\n",
    "            if iter % print_every == 0:\n",
    "                print('epoch: %d, batch: %d, loss: %f' % (epoch, iter, loss_i.item()))\n",
    "                # save the reconstructed inference\n",
    "\n",
    "                y = torch.arange(0, 10).long().unsqueeze(1)\n",
    "                y_onehot = idx2onehot(y, n=10)\n",
    "                y_onehot = y_onehot.cuda()\n",
    "                x = cvae.gen_forward(y_onehot)\n",
    "\n",
    "                plt.figure()\n",
    "                plt.figure(figsize=(5, 10))\n",
    "                for p in range(10):\n",
    "                    plt.subplot(5, 2, p+1)\n",
    "                    plt.text(\n",
    "                        0, 0, \"y={:d}\".format(y[p].item()), color='black',\n",
    "                        backgroundcolor='white', fontsize=8)\n",
    "                    plt.imshow(x[p].cpu().view(28, 28).data.numpy())\n",
    "                    plt.axis('off')\n",
    "                fig_root = 'plots'\n",
    "                os.makedirs(os.path.join(fig_root), exist_ok=True)\n",
    "                plt.savefig(\n",
    "                    os.path.join(fig_root,\n",
    "                                 \"epoch{:d}batch{:d}.png\".format(epoch, iter)),\n",
    "                    dpi=300)\n",
    "                plt.clf()\n",
    "                plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "start training...\nepoch: 0, batch: 0, loss: 4777.126953\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-8c07e6bbd761>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m                         \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y={:d}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                         backgroundcolor='white', fontsize=8)\n\u001b[0;32m---> 75\u001b[0;31m                     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m                     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0mfig_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'plots'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}