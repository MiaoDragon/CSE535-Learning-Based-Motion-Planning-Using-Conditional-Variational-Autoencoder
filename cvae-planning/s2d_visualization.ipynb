{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize the trained model\n",
    "\n",
    "import sys\n",
    "#sys.path.append('deps/sparse_rrt')\n",
    "sys.path.append('.')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import importlib\n",
    "#from model import ae_s2d\n",
    "#from model import cvae_s2d_model1 as cvae_s2d\n",
    "\n",
    "from model.SMPNet import SMPNet\n",
    "from model.SMPPathNet import SMPPathNet\n",
    "from model.SMPPathWithPriorNet import SMPPathWithPriorNet\n",
    "\n",
    "#from tools import data_loader\n",
    "from tools.utility import *\n",
    "#from plan_utility import cart_pole, cart_pole_obs, pendulum, acrobot_obs, car_obs\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm, trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(param_name='cvae_s2d_param3.yaml', param_path='param/train/')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-9e48851f11ea>:16: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  param = yaml.load(param_f)\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "# try:\n",
    "#     from yaml import CLoader as Loader, CDumper as Dumper\n",
    "# except ImportError:\n",
    "#     from yaml import Loader, Dumper\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "# for training\n",
    "parser.add_argument('--param_path', type=str, default='param/train/',help='path for loading training param')\n",
    "parser.add_argument('--param_name', type=str, default=\"cvae_s2d_param3.yaml\")\n",
    "\n",
    "# parse the parameter file\n",
    "args = parser.parse_args(\"\")\n",
    "print(args)\n",
    "param_f = open(args.param_path+args.param_name, 'r')\n",
    "param = yaml.load(param_f)\n",
    "param = DictDot(param)\n",
    "args = param\n",
    "args.start_epoch = 3\n",
    "args.s = 0\n",
    "args.sp = 6000\n",
    "args.start_iter =  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the output of one encoder\n",
      "343\n",
      "SMPPathWithPriorNet\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(args.device)\n",
    "# environment setting\n",
    "cae = None\n",
    "mlp = None\n",
    "\n",
    "# load net\n",
    "# load previously trained model if start epoch > 0\n",
    "\n",
    "# dynamically import model\n",
    "ae_module = importlib.import_module('model.ae_%s_model_%d' % (args.env_type, args.model_id))\n",
    "cvae_module = importlib.import_module('model.cvae_%s_model_%d' % (args.env_type, args.model_id))\n",
    "e_net = ae_module.Encoder(input_size=args.e_net_input_size, output_size=args.e_net_output_size)\n",
    "cvae = cvae_module.CVAE(input_size=args.input_size, latent_size=args.latent_size, cond_size=args.cond_size)\n",
    "\n",
    "data_loader = importlib.import_module('tools.data_loader_%s' % (args.env_type))\n",
    "plan_util = importlib.import_module('plan_util.%s' % (args.env_type))\n",
    "normalize = plan_util.normalize\n",
    "unnormalize = plan_util.unnormalize\n",
    "\n",
    "if args.model_type == \"SMPNet\":\n",
    "    smpnet = SMPNet(e_net, cvae)\n",
    "elif args.model_type == \"SMPPathNet\":\n",
    "    smpnet = SMPPathNet(e_net, cvae)\n",
    "elif args.model_type == \"SMPPathWithPriorNet\":\n",
    "    smpnet = SMPPathWithPriorNet(e_net, cvae)\n",
    "\n",
    "\n",
    "model_dir = args.model_dir + '%s/%s/model_%d/param_%s/' % (args.env_type, args.model_type, args.model_id, args.param_name)\n",
    "model_path='smpnet_epoch_%d_iter_%d.pkl' %(args.start_epoch, args.start_iter)\n",
    "torch_seed, np_seed, py_seed = 0, 0, 0\n",
    "if args.start_epoch > 0:\n",
    "    load_net_state(smpnet, os.path.join(model_dir, model_path))\n",
    "    torch_seed, np_seed, py_seed = load_seed(os.path.join(model_dir, model_path))\n",
    "    # set seed after loading\n",
    "    torch.manual_seed(torch_seed)\n",
    "    np.random.seed(np_seed)\n",
    "    random.seed(py_seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    smpnet.cuda()\n",
    "    smpnet.cvae.cuda()\n",
    "    smpnet.e_net.cuda()\n",
    "    if args.opt == 'Adagrad':\n",
    "        smpnet.set_opt(torch.optim.Adagrad, lr=args.learning_rate)\n",
    "    elif args.opt == 'Adam':\n",
    "        smpnet.set_opt(torch.optim.Adam, lr=args.learning_rate)\n",
    "    elif args.opt == 'SGD':\n",
    "        smpnet.set_opt(torch.optim.SGD, lr=args.learning_rate, momentum=0.9)\n",
    "    elif args.opt == 'ASGD':\n",
    "        smpnet.set_opt(torch.optim.ASGD, lr=args.learning_rate)\n",
    "if args.start_epoch > 0:\n",
    "    load_opt_state(smpnet, os.path.join(model_dir, model_path))\n",
    "data_folder = args.data_folder+args.env_type+'/'\n",
    "print(args.model_type)\n",
    "load_dis_ratio = None\n",
    "if args.model_type == \"SMPPathNet\":\n",
    "    load_dis_ratio = True\n",
    "elif args.model_type == \"SMPPathWithPriorNet\":\n",
    "    load_dis_ratio = True\n",
    "elif args.model_type == \"SMPNet\":\n",
    "    load_dis_ratio = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss: 0.007956\n"
     ]
    }
   ],
   "source": [
    "# test to see the error\n",
    "waypoint_dataset, cond_dataset, obs, env_indices \\\n",
    "         = data_loader.load_train_dataset(N=10, NP=200, s=0, sp=0,\n",
    "                                            data_folder=data_folder, load_dis_ratio=load_dis_ratio)\n",
    "cond_dataset = np.array(cond_dataset)\n",
    "# randomize the dataset before training\n",
    "data=list(zip(waypoint_dataset, cond_dataset, env_indices))\n",
    "random.shuffle(data)\n",
    "waypoint_dataset,cond_dataset,env_indices=list(zip(*data))\n",
    "waypoint_dataset = list(waypoint_dataset)\n",
    "cond_dataset = list(cond_dataset)\n",
    "env_indices = list(env_indices)\n",
    "waypoint_dataset = np.array(waypoint_dataset)\n",
    "cond_dataset = np.array(cond_dataset)\n",
    "env_indices = np.array(env_indices)\n",
    "\n",
    "smpnet.eval()\n",
    "epoch_val_num = 2048\n",
    "waypoint_dataset_i = waypoint_dataset[:epoch_val_num]\n",
    "cond_dataset_i = cond_dataset[:epoch_val_num]\n",
    "env_indices_i = env_indices[:epoch_val_num]\n",
    "bi = waypoint_dataset_i\n",
    "bi = torch.FloatTensor(bi)\n",
    "bi = normalize(bi, args.world_size)\n",
    "bi=to_var(bi)\n",
    "\n",
    "cond_dataset_i = torch.FloatTensor(cond_dataset_i)\n",
    "cond_dataset_i = normalize(cond_dataset_i, args.world_size)  # assume the first Sx2 are start and goal\n",
    "cond_dataset_i = to_var(cond_dataset_i)\n",
    "\n",
    "bobs = obs[env_indices_i].astype(np.float32)\n",
    "bobs = torch.FloatTensor(bobs)\n",
    "bobs = to_var(bobs)\n",
    "loss = smpnet.loss(bi, smpnet.train_forward(bi, cond_dataset_i, bobs), beta=args.beta)\n",
    "loss = torch.mean(loss)\n",
    "print('mean loss: %f' % (loss.cpu().item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss: 0.011042\n",
      "generation loss: 0.011560\n",
      "KL loss: 0.000031\n",
      "reconstruction: \n",
      "tensor([[[-0.5342,  0.5850],\n",
      "         [ 0.2837,  0.8069],\n",
      "         [ 0.0026,  0.7070],\n",
      "         [ 0.3627,  0.8541],\n",
      "         [-0.2625,  0.6435],\n",
      "         [-0.7754,  0.6569]]], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "torch.Size([1, 6, 2])\n",
      "ground truth:\n",
      "tensor([[-0.5430,  0.7476],\n",
      "        [ 0.3043,  0.9152],\n",
      "        [-0.0288,  0.8600],\n",
      "        [ 0.4537,  0.9093],\n",
      "        [-0.2525,  0.8086],\n",
      "        [-0.9673,  0.6481]])\n",
      "condition:\n",
      "tensor([[-0.9673,  0.6481,  0.4537,  0.9093,  0.3007],\n",
      "        [-0.9673,  0.6481,  0.4537,  0.9093,  0.8968],\n",
      "        [-0.9673,  0.6481,  0.4537,  0.9093,  0.6639],\n",
      "        [-0.9673,  0.6481,  0.4537,  0.9093,  1.0000],\n",
      "        [-0.9673,  0.6481,  0.4537,  0.9093,  0.5055],\n",
      "        [-0.9673,  0.6481,  0.4537,  0.9093,  0.0000]], device='cuda:0')\n",
      "prior_z_mu:\n",
      "tensor([[-0.0296, -0.0049],\n",
      "        [-0.0291, -0.0012],\n",
      "        [-0.0296, -0.0018],\n",
      "        [-0.0291, -0.0010],\n",
      "        [-0.0299, -0.0030],\n",
      "        [-0.0284, -0.0056]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "prior_z_log_sigma_pow2:\n",
      "tensor([[-0.2410, -0.3382],\n",
      "        [-0.2585, -0.3475],\n",
      "        [-0.2522, -0.3437],\n",
      "        [-0.2612, -0.3493],\n",
      "        [-0.2474, -0.3413],\n",
      "        [-0.2320, -0.3367]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "rec_z_mu:\n",
      "tensor([[-0.0303, -0.0040],\n",
      "        [-0.0300, -0.0029],\n",
      "        [-0.0301, -0.0034],\n",
      "        [-0.0300, -0.0027],\n",
      "        [-0.0302, -0.0037],\n",
      "        [-0.0302, -0.0044]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "rec_z_log_sigma_pow2:\n",
      "tensor([[-0.2330, -0.3327],\n",
      "        [-0.2481, -0.3436],\n",
      "        [-0.2412, -0.3387],\n",
      "        [-0.2511, -0.3458],\n",
      "        [-0.2373, -0.3358],\n",
      "        [-0.2274, -0.3286]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "obs_idx = 3\n",
    "path_idx = 150\n",
    "\n",
    "# test to see the error\n",
    "waypoint_dataset, cond_dataset, obs, env_indices \\\n",
    "         = data_loader.load_train_dataset(N=1, NP=1, s=args.s+obs_idx, sp=args.sp+path_idx,\n",
    "                                            data_folder=data_folder, load_dis_ratio=load_dis_ratio)\n",
    "\n",
    "cond_dataset = np.array(cond_dataset)\n",
    "# randomize the dataset before training\n",
    "data=list(zip(waypoint_dataset, cond_dataset, env_indices))\n",
    "random.shuffle(data)\n",
    "waypoint_dataset,cond_dataset,env_indices=list(zip(*data))\n",
    "waypoint_dataset = list(waypoint_dataset)\n",
    "cond_dataset = list(cond_dataset)\n",
    "env_indices = list(env_indices)\n",
    "waypoint_dataset = np.array(waypoint_dataset)\n",
    "cond_dataset = np.array(cond_dataset)\n",
    "env_indices = np.array(env_indices)\n",
    "\n",
    "smpnet.eval()\n",
    "epoch_val_num = 2048\n",
    "waypoint_dataset_i = waypoint_dataset[:epoch_val_num]\n",
    "cond_dataset_i = cond_dataset[:epoch_val_num]\n",
    "env_indices_i = env_indices[:epoch_val_num]\n",
    "bi = waypoint_dataset_i\n",
    "bi = torch.FloatTensor(bi)\n",
    "bi = normalize(bi, args.world_size)\n",
    "bi=to_var(bi)\n",
    "\n",
    "cond_dataset_i = torch.FloatTensor(cond_dataset_i)\n",
    "cond_dataset_i = normalize(cond_dataset_i, args.world_size)  # assume the first Sx2 are start and goal\n",
    "cond_dataset_i = to_var(cond_dataset_i)\n",
    "\n",
    "bobs = obs[env_indices_i].astype(np.float32)\n",
    "bobs = torch.FloatTensor(bobs)\n",
    "bobs = to_var(bobs)\n",
    "loss = smpnet.loss(bi, smpnet.train_forward(bi, cond_dataset_i, bobs), beta=args.beta)\n",
    "loss = torch.mean(loss)\n",
    "print('mean loss: %f' % (loss.cpu().item()))\n",
    "\n",
    "output = smpnet.train_forward(bi, cond_dataset_i, bobs, L=1)\n",
    "gen_loss = smpnet.generation_loss(bi, output)\n",
    "gen_loss = torch.mean(gen_loss)\n",
    "print('generation loss: %f' % (gen_loss.cpu().item()))\n",
    "\n",
    "kl_loss = smpnet.kl_divergence(bi, output)\n",
    "kl_loss = torch.mean(kl_loss)\n",
    "print('KL loss: %f' % (kl_loss.cpu().item()))\n",
    "\n",
    "prior_z_mu, prior_z_log_sigma_pow2, z_mu,z_log_sigma_pow2, z, x_mu = output\n",
    "print('reconstruction: ')\n",
    "print(x_mu)\n",
    "print(x_mu.size())\n",
    "print('ground truth:')\n",
    "print(bi.cpu().data)\n",
    "\n",
    "print('condition:')\n",
    "print(cond_dataset_i[:10])\n",
    "\n",
    "print('prior_z_mu:')\n",
    "print(prior_z_mu)\n",
    "print('prior_z_log_sigma_pow2:')\n",
    "print(prior_z_log_sigma_pow2)\n",
    "\n",
    "print('rec_z_mu:')\n",
    "print(z_mu)\n",
    "print('rec_z_log_sigma_pow2:')\n",
    "print(z_log_sigma_pow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading...\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "print('loading...')\n",
    "obs_center, obs, paths, path_lengths = \\\n",
    "        data_loader.load_test_dataset(N=args.no_env, NP=args.no_motion_paths, \\\n",
    "                                      s=args.s, sp=args.sp, folder=data_folder)\n",
    "obs_width = 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "def cvae_visualization(smpnet, obs_idx, path_idx, dist_val, num_sample=10):\n",
    "    # visualize the planning scene and samples\n",
    "    obs_center_i = obs_center[obs_idx]\n",
    "    obs_i = obs[obs_idx]\n",
    "    path_i = paths[obs_idx][path_idx]\n",
    "    path_length_i = path_lengths[obs_idx][path_idx]\n",
    "    #print(path_length_i)\n",
    "    assert path_length_i > 2\n",
    "    #dist = np.linspace(0., 1., 10)\n",
    "    dist = np.array([dist_val])\n",
    "    #print(dist)\n",
    "    dist = np.repeat(dist, num_sample).reshape(-1,1)\n",
    "\n",
    "    #dist = np.repeat(dist, num_sample//10).reshape(-1,1)\n",
    "    #print(dist.shape)\n",
    "    start_i = np.array([path_i[0]])\n",
    "    goal_i = np.array([path_i[path_length_i-1]])\n",
    "    start_i = np.tile(start_i, [num_sample, 1])\n",
    "    goal_i = np.tile(goal_i, [num_sample, 1])\n",
    "    cond_dataset_i = np.concatenate([start_i, goal_i, dist], axis=1)\n",
    "    cond_dataset_i = torch.FloatTensor(cond_dataset_i)\n",
    "    cond_dataset_i = normalize(cond_dataset_i, args.world_size)  # assume the first Sx2 are start and goal\n",
    "    cond_dataset_i = to_var(cond_dataset_i)\n",
    "    \n",
    "    #print([num_sample]+list(obs_i.shape))\n",
    "    bobs = torch.FloatTensor(obs_i).unsqueeze(0).repeat([num_sample, 1, 1, 1])\n",
    "    bobs = to_var(bobs)\n",
    "    #print(bobs.size())\n",
    "    \n",
    "    \n",
    "    # generating\n",
    "    samples = smpnet.gen_forward(cond_dataset_i, obs=bobs, obs_z=None)\n",
    "    samples = samples.cpu().data\n",
    "    samples = unnormalize(samples, args.world_size).numpy()\n",
    "    \n",
    "    # visualize\n",
    "    # show obstacles\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlim(-22, 22)\n",
    "    ax.set_ylim(-22, 22)\n",
    "    #print(obs_center_i.shape)\n",
    "\n",
    "    for i in range(len(obs_center_i)):\n",
    "        x, y = obs_center_i[i][0], obs_center_i[i][1]\n",
    "        obs_patch_i = patches.Rectangle((x-obs_width/2,y-obs_width/2),\\\n",
    "                                       obs_width,obs_width,\\\n",
    "                                       linewidth=0.0, facecolor='black')\n",
    "        ax.add_patch(obs_patch_i)\n",
    "    \n",
    "    # show start and goal\n",
    "    ax.scatter([path_i[0][0]], [path_i[0][1]], c='green', s=100.0)\n",
    "    ax.scatter([path_i[path_length_i-1][0]], [path_i[path_length_i-1][1]], c='red', s=100.0, marker='*')\n",
    "    \n",
    "    # show path\n",
    "    ax.plot(path_i[:path_length_i,0], path_i[:path_length_i,1], c='pink')\n",
    "    ax.scatter(path_i[1:-1,0], path_i[1:-1,1], c=\"pink\", s=100)\n",
    "    # show samples\n",
    "    ax.scatter(samples[:,0], samples[:,1], c='blue', s=50.)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = cvae_visualization(smpnet, 1, 140, dist_val=0.1,num_sample=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  5  9 ...  0  0  0]\n",
      " [14  6  9 ...  0  0  0]\n",
      " [ 2 17  6 ...  0  0  0]\n",
      " ...\n",
      " [14  5  6 ...  0  0  0]\n",
      " [10 17  7 ...  0  0  0]\n",
      " [ 3 21  2 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(path_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['smpnet_epoch_1_iter_0.pkl', 'smpnet_epoch_1_iter_2000.pkl', 'smpnet_epoch_1_iter_4000.pkl', 'smpnet_epoch_1_iter_6000.pkl', 'smpnet_epoch_1_iter_8000.pkl', 'smpnet_epoch_1_iter_10000.pkl', 'smpnet_epoch_2_iter_0.pkl', 'smpnet_epoch_2_iter_2000.pkl', 'smpnet_epoch_2_iter_4000.pkl', 'smpnet_epoch_2_iter_6000.pkl', 'smpnet_epoch_2_iter_8000.pkl', 'smpnet_epoch_2_iter_10000.pkl']\n"
     ]
    }
   ],
   "source": [
    "model_fs = [f for f in os.listdir(model_dir) if 'smpnet_epoch_' in f and 'iter' in f]\n",
    "def get_epoch_itr(v_str):\n",
    "    idx = v_str.split('epoch_')[1]\n",
    "    idx = idx.split('_iter_')\n",
    "    epoch = int(idx[0])\n",
    "    itr = int(idx[1][:-4])\n",
    "    return (epoch, itr)\n",
    "model_fs = sorted(model_fs, key=get_epoch_itr)\n",
    "print(model_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_figs(obs_idx, path_idx, num_dist, num_sample=100):\n",
    "    for model_f in model_fs:\n",
    "        if model_f == 'smpnet_epoch_10_iter_1000.pkl':\n",
    "            continue\n",
    "        smpnet = SMPNet(e_net, cvae)\n",
    "        smpnet.eval()\n",
    "        model_path=model_f\n",
    "        load_net_state(smpnet, os.path.join(model_dir, model_path))\n",
    "        torch_seed, np_seed, py_seed = load_seed(os.path.join(model_dir, model_path))\n",
    "        # set seed after loading\n",
    "        torch.manual_seed(torch_seed)\n",
    "        np.random.seed(np_seed)\n",
    "        random.seed(py_seed)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            smpnet.cuda()\n",
    "            smpnet.cvae.cuda()\n",
    "            smpnet.e_net.cuda()\n",
    "        dist_vals = np.linspace(0.,1.,num_dist)\n",
    "        for dist_val in dist_vals:\n",
    "            fig = cvae_visualization(smpnet, obs_idx, path_idx, dist_val, num_sample=num_sample);\n",
    "            os.makedirs('plots/%s/param_%d/' % (args.model_type, args.param_name), exist_ok=True)\n",
    "            plt.savefig(\"plots/%s/param_%d/env_%d_path_%d_dist_%f_%s.png\" % (args.model_type, args.param_name, \\\n",
    "                                                                            obs_idx+args.s, path_idx+args.sp, \\\n",
    "                                                                            dist_val, model_f[:-4]));\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in /ilab/users/ym420/miniconda3/envs/cse535/lib/python3.8/site-packages (2.9.0)\r\n",
      "Requirement already satisfied: pillow in /ilab/users/ym420/miniconda3/envs/cse535/lib/python3.8/site-packages (from imageio) (8.0.0)\r\n",
      "Requirement already satisfied: numpy in /ilab/users/ym420/miniconda3/envs/cse535/lib/python3.8/site-packages (from imageio) (1.19.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "def make_video(obs_idx, path_idx, dist_val):\n",
    "    def tryint(s):\n",
    "        try:\n",
    "            return int(s)\n",
    "        except ValueError:\n",
    "            return s\n",
    "    def str2int(v_str):\n",
    "        idx = v_str.split('epoch_')[1]\n",
    "        idx = int(idx[:-4])\n",
    "        return idx\n",
    "    def get_epoch_itr(v_str):\n",
    "        idx = v_str.split('epoch_')[1]\n",
    "        idx = idx.split('_iter_')\n",
    "        epoch = int(idx[0])\n",
    "        itr = int(idx[1][:-4])\n",
    "        return (epoch, itr)\n",
    "\n",
    "    def sort_humanly(v_list):\n",
    "        return sorted(v_list, key=get_epoch_itr)\n",
    "    image_folder = 'plots/%s/param_%d/' % (args.model_type, args.param_name)\n",
    "    \n",
    "    os.makedirs('video/%s/param_%d' % (args.model_type, args.param_name), exist_ok=True)\n",
    "    video_name = 'video/{}/param_{}/env_{}_path_{}_dist_{}.gif'.format(args.model_type, args.param_name, obs_idx, path_idx, dist_val)\n",
    "    images = [img for img in os.listdir(image_folder) \\\n",
    "              if 'env_%d_path_%d' % (obs_idx+args.s, path_idx+args.sp) in img and 'iter' in img \\\n",
    "                 and 'dist_%f' % (dist_val) in img]\n",
    "    images = sort_humanly(images)\n",
    "    imgs = []\n",
    "    for filename in images:\n",
    "#         print('./'+image_folder+'/'+filename)\n",
    "        imgs.append(imageio.imread('./'+image_folder+'/'+filename))\n",
    "    imageio.mimsave(video_name, imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 1\n",
      "count: 2\n",
      "count: 1\n",
      "count: 2\n",
      "count: 1\n",
      "count: 2\n",
      "count: 1\n",
      "count: 2\n",
      "count: 1\n"
     ]
    }
   ],
   "source": [
    "# save figure for different model\n",
    "for obs_idx in range(10):\n",
    "    path_idxs = []\n",
    "    count = 0\n",
    "    while True:\n",
    "        path_idx = np.random.choice(200)\n",
    "        if path_lengths[obs_idx][path_idx] < 5:\n",
    "            continue\n",
    "        if path_idx in path_idxs:\n",
    "            continue\n",
    "        count += 1\n",
    "        path_idxs.append(path_idx)\n",
    "        num_dist = 11\n",
    "        gen_figs(obs_idx, path_idx, num_dist=num_dist, num_sample=20)\n",
    "        dist_vals = np.linspace(0.,1.,num_dist)\n",
    "        for dist_val in dist_vals:\n",
    "            make_video(obs_idx, path_idx, dist_val)\n",
    "        print('count: %d' % (count))\n",
    "        if count == 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_video(obs_idx+args.s, path_idx+args.sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cse535] *",
   "language": "python",
   "name": "conda-env-cse535-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
